{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launching parallel jobs on a Slurm Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to read the notebook on `Sweeping over hyperparameters`\n",
    "\n",
    "Launching several jobs can be very useful to try a lot of different hyperparameter combinations like : trying multiple NN architectures, different optimizers, different seeds, etc..\n",
    "\n",
    "In this notebook, we will see how to use Hydra and GenFL to launch multiple runs in a parallel fashion on a Slurm Cluster. Of course, you need access to a computational cluster which is monitored by Slurm.\n",
    "\n",
    "Hydra has a built-in functionality to do \"sbatch\" command from slurm in a easy and configurable way. We will use the [Submitit launcher](https://hydra.cc/docs/plugins/submitit_launcher/), I recommend you to read the guide from hydra. \n",
    "\n",
    "Once you have read the webpage, you can check that there is `./conf/hydra/launcher/custom.yaml` which can be used to configure the slurm's jobs (like in a sbatch file).\n",
    "\n",
    "Once you have parameterised this config file and you want to launch your command (let's say the one from the `Sweeping over hyperparameters` notebook):\n",
    "\n",
    "Then on the cluster frontal machine, where your code GenFL is, you put exactly the same command with additional `hydra/launcher=custom` (`--multirun` option is mandatory when using `subtmitit_launcher`):\n",
    "\n",
    "```bash\n",
    "\n",
    "python GenFL_posterior.py --multirun \\\n",
    "    +scenario=perez_posterior_rand \\\n",
    "    +experiment=sweep_over_seeds_and_objectives \\\n",
    "    hydra/launcher=custom    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
